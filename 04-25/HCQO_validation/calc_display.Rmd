---
title: "HCQO validation and calculation codes v3.0"
author: "Aksel Betkas, Kadri-Ann Kallas, Elise Barattini"
date: "2023/24"
output: html_document
---

# This is a Rmarkdown code to be run on data files from the OECD HCQO data collection. 

### Here we set up R and if necessary, download the R libraries you need to run the code
To run the codes, you will need to 
  1. have downloaded the folder called HCQO_validation
  2. install the necessary R packages (R should let you know which ones are necessary)
  3. copy .csv files you wish to analyse into the folder HCQO_validation\data*
  4. Run the code in the gray boxes without any changes

To learn how to run code on R and more about the software and packages, you could see material at: https://education.rstudio.com/learn/beginner/

*Note that indicators in Patient Experiences (PE) and Mental Health PREMs (MP) (that do not require calculations) are not currently eligible for processing with this code.




### (1)  Setup
This section loads the R packages necessary to run the script, sets the working directory of the user in order to be able to access the files, and calls predefined functions (can be viewed in the HCQO_validation/function folder) that will be used in the script. It displays the input data as data.tables as is to verify that the expected files are loaded.
```{r}
### 1. load the packages
# if the packages are not installed yet, you can install them manually by copying the next line (without #) in the console
# install.packages(c("dplyr", "tidyr", "ggplot2", "DT", "shinydashboard", "shiny", "forcats"))

library(dplyr)
library(tidyr)
library(ggplot2)
library(DT)
library(shinydashboard)
library(shiny)
library(forcats)
library(data.table)

### 2. define the path to the folders
# the paths should not be changed and should run if the files are saved correctly
path <- {"../HCQO_validation"}
setwd(path)
file_paths <- list.files("data", pattern = "\\.csv$", full.names = TRUE, recursive = TRUE)

alll <- list()

### 3. call the functions
## data import function
source("functions/load_csv.R")

## validation checks functions
source("functions/validate_missing_denom.R")
source("functions/validate_rates.R")
source("functions/validate_format.R")

## calculate rates function
source("functions/calculate_indicator.R")

### 4. preview the input data 
file_paths <- list.files("data", pattern = "\\.csv$", full.names = TRUE, recursive = TRUE)

# Apply the function to each file path
lapply(file_paths, load_csv)
```




### (2) Data Validation
This section applies validation checks to the data to verify it. The current validation checks performed are the following:
- Validation Check 1: verifies data format, including column names and values
- Validation Check 2: verifies whether any numerators have no matching denominators
- Validation Check 3: verifies whether there are any rates where the corresponding NUM > DEN
```{r}
all_data <- list()

for (file_path in file_paths) { # load the files one by one
    df_raw <- load_csv(file_path)
    if (!is.null(df_raw)) { # does not process empty files
        file_name <- basename(file_path)
        print(paste("Processing file:", file_name)) # outputs which file is currently being processed
        
        # Perform validation checks
        col_names_validated <- validate_format(df_raw, file_name) # validation check 1
        if (!col_names_validated) {
            next  # Skip further processing if column names are incorrect
        }
        
        validate_missing_denom(df_raw, file_name) # validation check 2
        validate_rates(df_raw, file_name) # validation check 3
        
        # append data if all validations pass
        all_data[[file_name]] <- df_raw
    }
}

```



### (3) Calculate Rates
```{r}

# Use lapply to apply CalculateIndicator to each file path
results_individual <- lapply(file_paths, CalculateIndicator)

# Combine the results into a single dataframe
results_combined <- dplyr::bind_rows(results_individual)


# Combine the different csvs
results_combined <- dplyr::bind_rows(results_individual)

# Remove all white spaces from MEASURE column
results_combined$MEASURE <- gsub("\\s", "", results_combined$MEASURE) 

# Merge value names to each dataframe
value_keys <- read.csv("value_mapping.csv", header = TRUE,
                       colClasses =list('MEASURE' = "character",
                                          'value' = "character" ) )

# join results and keys based on indicator name
merged_df <- merge(results_combined, value_keys, by = "MEASURE", all.x = TRUE)

# Add confidence interval values
merged_df$value.y <-ifelse(merged_df$value.x %in% c('lo_ci', 'up_ci'), yes = merged_df$value.x, no =  merged_df$value.y)


# Drop old column and rename columns appropriately
merged_df <- merged_df %>%  select(-value.x) %>% 
             rename(c(UNIT = value.y, OBS_VALUE = number))

```



## (4) Dashboard
```{r}
source("functions/dashboard_setup.R")
shinyApp(ui, server)
```


## (5) Generate the output file
```{r}
# Current date and time in DDMMYYYY_HHMM format
date.suffix <- format(Sys.time(), "%d%m%Y_%H%M")

# Add the date and time suffix to the file name
file.name <- paste0("results_" , date.suffix, ".csv")
file.name.full <- file.path('./results', file.name) # name output path

# Save the file with the date and time suffix
write.csv(merged_df, file = file.name.full, row.names = FALSE)

# Print message once the csv file has been saved
message("Results file successfully saved")

```


